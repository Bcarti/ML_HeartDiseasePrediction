{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto ML - Heart disease prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Importaci√≥n de librer√≠as\n",
    "\n",
    "Se importan todas las librer√≠as necesarias para la carga de datos, preprocesamiento, modelado, evaluaci√≥n y visualizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Carga y limpieza del dataset\n",
    "\n",
    "Se carga el dataset desde el archivo CSV, se renombran las columnas, se eliminan los valores desconocidos y se convierte la variable objetivo en binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la ruta absoluta del directorio ra√≠z del proyecto\n",
    "ruta_proyecto = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "# Construir la ruta al dataset\n",
    "ruta_csv = os.path.join(ruta_proyecto, \"data_sample/cleveland_heart_disease.csv\")\n",
    "\n",
    "# Cargar el dataset\n",
    "column_names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
    "                \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
    "df = pd.read_csv(ruta_csv, names=column_names)\n",
    "\n",
    "# Asegurar que todos los valores son strings antes de reemplazar\n",
    "df = df.map(lambda x: str(x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Reemplazar \"?\" por NaN\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "# La convierto a clasificacion binaria\n",
    "df[\"target\"] = df[\"target\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "print(df[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Divisi√≥n de datos en entrenamiento y prueba\n",
    "\n",
    "Se separan las variables predictoras (`X`) de la variable objetivo (`y`) y se divide el conjunto en entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separar en variables predictoras (X) y target (y)\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Preprocesamiento de datos\n",
    "\n",
    "Se definen pipelines para el tratamiento de variables num√©ricas y categ√≥ricas, y se integran mediante un `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Separar columnas num√©ricas y categ√≥ricas\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 1.1 Pipeline para variables num√©ricas: imputaci√≥n + escalado\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 1.2 Pipeline para variables categ√≥ricas: imputaci√≥n + codificaci√≥n one-hot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# 2. Pipelines de preprocesamiento: \n",
    "# 2.1 Pipeline para variables num√©ricas: imputaci√≥n + escalado\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2.2 Pipeline para variables categ√≥ricas: imputaci√≥n + codificaci√≥n one-hot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. ColumnTransformer para aplicar el preprocesamiento seg√∫n tipo de variable\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Entrenamiento de modelo principal (XGBoost) con GridSearchCV\n",
    "\n",
    "Se define un pipeline completo con `XGBoost` y se realiza una b√∫squeda de hiperpar√°metros usando validaci√≥n cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Pipeline final: preprocesamiento + modelo XGBClassifier\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "# 4. B√∫squeda de hiperpar√°metros con GridSearchCV\n",
    "# 4.1 Definici√≥n de la rejilla de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "# 4.2 B√∫squeda con validaci√≥n cruzada\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='recall')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predicciones y evaluaci√≥n\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Evaluaci√≥n y exportaci√≥n de modelos adicionales\n",
    "\n",
    "Se entrenan varios modelos supervisados, se eval√∫an sus m√©tricas y se exportan en formato `.joblib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde guardo los modelos\n",
    "ruta_modelos = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(ruta_modelos, exist_ok=True)\n",
    "print(\"Ruta absoluta donde se guardar√°n los modelos:\", os.path.abspath(ruta_modelos))\n",
    "\n",
    "\n",
    "# Diccionario con los modelos a evaluar\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVC\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Lista para guardar resultados\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüîç Entrenando modelo: {model_name}\")\n",
    "    \n",
    "    # Crear pipeline con preprocesamiento + modelo\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Guardar m√©tricas\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": round(accuracy, 3),\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"F1-Score\": round(f1, 3)\n",
    "    })\n",
    "\n",
    "    # Guardar modelo en src/models correctamente\n",
    "    path_modelo = os.path.join(ruta_modelos, f\"{model_name}.joblib\")\n",
    "    joblib.dump(pipeline, path_modelo)\n",
    "    print(f\"‚úÖ Modelo {model_name} guardado en: {path_modelo}\")\n",
    "    print(\"¬øEl archivo existe?\", os.path.isfile(path_modelo))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "df_results = pd.DataFrame(results).sort_values(by=\"F1-Score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Comparaci√≥n de resultados\n",
    "\n",
    "Se muestra una tabla con los resultados de todos los modelos, ordenados por F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà Comparativa de modelos (ordenados por F1-Score):\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Visualizaci√≥n de m√©tricas\n",
    "\n",
    "Se generan gr√°ficos comparativos para F1-Score y Recall entre los modelos entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico general: F1-Score de todos los modelos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_results[\"Model\"], df_results[\"F1-Score\"], color='skyblue')\n",
    "plt.title(\"Comparaci√≥n de F1-Score entre modelos\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gr√°fico comparativo: F1-Score y Recall lado a lado\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "index = range(len(df_results))\n",
    "\n",
    "plt.bar(index, df_results[\"F1-Score\"], bar_width, label=\"F1-Score\", color=\"cornflowerblue\")\n",
    "plt.bar([i + bar_width for i in index], df_results[\"Recall\"], bar_width, label=\"Recall\", color=\"lightcoral\")\n",
    "\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Comparaci√≥n F1-Score y Recall entre modelos\")\n",
    "plt.xticks([i + bar_width / 2 for i in index], df_results[\"Model\"], rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
